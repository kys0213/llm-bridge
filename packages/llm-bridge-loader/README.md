# LLM Bridge Loader

A powerful and flexible dependency-based bridge loader for LLM Bridge packages. Automatically discover, validate, and load LLM bridges from your project dependencies.

## ğŸš€ Features

- **Automatic Discovery**: Automatically detects LLM bridge packages in dependencies
- **Dynamic Loading**: Loads bridges at runtime based on configuration
- **Type Safety**: Full TypeScript support with comprehensive type checking
- **Validation**: Validates bridge manifests and configurations using Zod schemas
- **Error Handling**: Robust error handling with detailed error messages
- **Extensible**: Easy to extend with custom bridge loaders

## ğŸ“¦ Installation

```bash
# pnpm (ê¶Œì¥)
pnpm add llm-bridge-loader llm-bridge-spec zod

# npm
npm install llm-bridge-loader llm-bridge-spec zod

# yarn
yarn add llm-bridge-loader llm-bridge-spec zod
```

## ğŸ¯ Quick Start

### Basic Usage

```typescript
import { DependencyBridgeLoader } from 'llm-bridge-loader';

// Create a loader instance
const loader = new DependencyBridgeLoader();

// Load a bridge by package name
const bridge = await loader.loadBridge('ollama-llm-bridge', {
  host: 'http://localhost:11434',
  model: 'llama3.2',
  temperature: 0.7,
});

// Use the bridge
const response = await bridge.invoke({
  messages: [{ role: 'user', content: [{ type: 'text', text: 'Hello!' }] }],
});

console.log(response.choices[0].message.content[0].text);
```

### Configuration-Based Loading

```typescript
import { DependencyBridgeLoader } from 'llm-bridge-loader';

const loader = new DependencyBridgeLoader();

// Load multiple bridges from configuration
const bridges = await loader.loadBridgesFromConfig([
  {
    name: 'ollama',
    package: 'ollama-llm-bridge',
    config: {
      host: 'http://localhost:11434',
      model: 'llama3.2',
      temperature: 0.7,
    },
  },
  {
    name: 'openai',
    package: 'openai-llm-bridge',
    config: {
      apiKey: process.env.OPENAI_API_KEY,
      model: 'gpt-4',
      temperature: 0.8,
    },
  },
]);

// Use specific bridge
const ollamaBridge = bridges.get('ollama');
const openAIBridge = bridges.get('openai');
```

## ğŸ§© Core Concepts

### Bridge Discovery

The loader automatically discovers LLM bridge packages by:

1. **Package Name Pattern**: Looking for packages ending with `-llm-bridge`
2. **Manifest Function**: Checking for a `manifest()` export
3. **Bridge Class**: Verifying the default export implements `LlmBridge`

### Bridge Loading Process

```typescript
// 1. Discover available bridges
const availableBridges = await loader.discoverBridges();

// 2. Get bridge information
const bridgeInfo = await loader.getBridgeInfo('ollama-llm-bridge');
console.log(bridgeInfo.manifest.capabilities);

// 3. Load and configure bridge
const bridge = await loader.loadBridge('ollama-llm-bridge', config);
```

## ğŸ“‹ API Reference

### `DependencyBridgeLoader`

Main class for loading LLM bridges from dependencies.

#### Methods

##### `loadBridge(packageName: string, config: unknown): Promise<LlmBridge>`

Loads a specific bridge with configuration.

```typescript
const bridge = await loader.loadBridge('ollama-llm-bridge', {
  model: 'llama3.2',
  temperature: 0.7,
});
```

##### `discoverBridges(): Promise<string[]>`

Discovers all available LLM bridge packages.

```typescript
const packages = await loader.discoverBridges();
console.log(packages); // ['ollama-llm-bridge', 'openai-llm-bridge', ...]
```

##### `getBridgeInfo(packageName: string): Promise<BridgePackageInfo>`

Gets detailed information about a bridge package.

```typescript
const info = await loader.getBridgeInfo('ollama-llm-bridge');
console.log(info.manifest.name);
console.log(info.manifest.capabilities);
```

##### `loadBridgesFromConfig(configs: BridgeConfig[]): Promise<Map<string, LlmBridge>>`

Loads multiple bridges from configuration array.

```typescript
const bridges = await loader.loadBridgesFromConfig([
  { name: 'ollama', package: 'ollama-llm-bridge', config: { model: 'llama3.2' } },
  { name: 'openai', package: 'openai-llm-bridge', config: { model: 'gpt-4' } },
]);
```

### Types

#### `BridgeConfig`

Configuration for loading a bridge.

```typescript
interface BridgeConfig {
  name: string;         // Unique identifier for the bridge
  package: string;      // Package name (e.g., 'ollama-llm-bridge')
  config: unknown;      // Bridge-specific configuration
}
```

#### `BridgePackageInfo`

Information about a bridge package.

```typescript
interface BridgePackageInfo {
  packageName: string;
  manifest: LlmManifest;
  bridgeClass: new (config: unknown) => LlmBridge;
}
```

## ğŸ” Bridge Discovery

### Automatic Discovery

The loader automatically scans your `node_modules` for packages that:

1. Have names ending with `-llm-bridge`
2. Export a `manifest()` function
3. Have a default export that implements `LlmBridge`

### Manual Bridge Registration

```typescript
// Register a custom bridge
loader.registerBridge('my-custom-bridge', {
  packageName: 'my-custom-bridge',
  manifest: myCustomManifest,
  bridgeClass: MyCustomBridge,
});
```

## âš™ï¸ Configuration Validation

The loader uses Zod schemas to validate bridge configurations:

```typescript
// Each bridge defines its own configuration schema
const ollamaSchema = z.object({
  host: z.string().url().optional(),
  model: z.string(),
  temperature: z.number().min(0).max(1).optional(),
});

// Loader validates config against the schema
const bridge = await loader.loadBridge('ollama-llm-bridge', {
  model: 'llama3.2',
  temperature: 0.7, // Validated against schema
});
```

## ğŸš¦ Error Handling

The loader provides detailed error information:

```typescript
import { 
  BridgeLoadError, 
  BridgeNotFoundError, 
  ConfigurationError 
} from 'llm-bridge-loader';

try {
  const bridge = await loader.loadBridge('unknown-bridge', {});
} catch (error) {
  if (error instanceof BridgeNotFoundError) {
    console.error('Bridge not found:', error.packageName);
    console.log('Available bridges:', error.availableBridges);
  } else if (error instanceof ConfigurationError) {
    console.error('Invalid configuration:', error.message);
    console.log('Validation errors:', error.validationErrors);
  }
}
```

## ğŸ§ª Testing

```bash
# Run unit tests
pnpm test

# Run tests with coverage
pnpm test:coverage

# Run in watch mode
pnpm test:watch
```

## ğŸ—ï¸ Architecture

```
llm-bridge-loader/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dependency/
â”‚   â”‚   â”œâ”€â”€ dependency-bridge.loader.ts    # Main loader implementation
â”‚   â”‚   â””â”€â”€ __tests__/
â”‚   â”œâ”€â”€ types.ts                           # Type definitions
â”‚   â””â”€â”€ index.ts                          # Entry point
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”— Related Packages

- [`llm-bridge-spec`](../llm-bridge-spec/) - Core interfaces and types
- [`ollama-llm-bridge`](../ollama-llm-bridge/) - Ollama bridge implementation
- [`openai-llm-bridge`](../openai-llm-bridge/) - OpenAI bridge implementation
- [`bedrock-llm-bridge`](../bedrock-llm-bridge/) - AWS Bedrock bridge implementation

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ì´ í”„ë¡œì íŠ¸ëŠ” [Git Workflow Guide](../../docs/GIT_WORKFLOW_GUIDE.md)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.

1. **Issues**: ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ë‚˜ ë²„ê·¸ ë¦¬í¬íŠ¸ë¥¼ GitHub Issuesì— ë“±ë¡
2. **ë¸Œëœì¹˜ ìƒì„±**: `git checkout -b feature/core-new-feature`
3. **TODO ê¸°ë°˜ ê°œë°œ**: ê° ì‘ì—…ì„ TODO ë‹¨ìœ„ë¡œ ì»¤ë°‹
   ```bash
   git commit -m "âœ… [TODO 1/3] Add new loader functionality"
   ```
4. **í’ˆì§ˆ ì²´í¬**: ì»¤ë°‹ ì „ ë°˜ë“œì‹œ í™•ì¸
   ```bash
   pnpm lint && pnpm test:ci && pnpm build
   ```
5. **PR ìƒì„±**: GitHubì—ì„œ Pull Request ìƒì„±
6. **ì½”ë“œ ë¦¬ë·°**: ìŠ¹ì¸ í›„ Squash Merge

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤.

---

**Made with â¤ï¸ by the LLM Bridge Team**